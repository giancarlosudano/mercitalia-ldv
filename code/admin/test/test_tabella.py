import streamlit as st
import os
import traceback
from datetime import datetime
import pandas as pd
from langchain_openai import AzureChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
import xml.etree.ElementTree as ET
import base64
import datetime
import glob
import json
import openai
import os
import requests
import sys

from dotenv import load_dotenv
from io import BytesIO
from PIL import Image

def plus_one():
	if st.session_state["slider"] < 10:
		st.session_state.slider += 1
	else:
		pass
	return

def check_openai_version():
	"""
	Check Azure Open AI version
	"""
	installed_version = openai.__version__

	try:
		version_number = float(installed_version[:3])
	except ValueError:
		print("Invalid OpenAI version format")
		return

	print(f"Installed OpenAI version: {installed_version}")

	if version_number < 1.0:
		print("[Warning] You should upgrade OpenAI to have version >= 1.0.0")
		print("To upgrade, run: %pip install openai --upgrade")
	else:
		print(f"[OK] OpenAI version {installed_version} is >= 1.0.0")
		
def GPT4V_with_AzureAIVision(image_file, prompt):

	openai.api_type: str = "azure"
	openai.api_key = os.getenv("AZURE_OPENAI_KEY")
	openai.api_base = os.getenv("AZURE_OPENAI_BASE")
	azure_aivision_endpoint = os.getenv("AZURE_AI_VISION_URL")
	azure_aivision_key = os.getenv("AZURE_AI_VISION_KEY")
	model = "GPT4Vision"
	
	if not os.path.exists(image_file):
		print(f"[Error] Image file {image_file} does not exist.")

	base_url = f"https://mtcmilanoaiswi.openai.azure.com/openai/deployments/gpt-4-vision-preview"
	gpt4vision_endpoint = (f"{base_url}/extensions/chat/completions?api-version=2023-12-01-preview")

	# Header
	headers = {"Content-Type": "application/json", "api-key": openai.api_key}

	# Encoded image
	base_64_encoded_image = base64.b64encode(open(image_file, "rb").read()).decode("ascii")

	# Context
	context = "You are an OCR AI expert. You will help to extarct information from tables in images."

	# Payload
	json_data = {
		"model": "gpt-4-vision-preview",
		"enhancements": {"ocr": {"enabled": True}, "grounding": {"enabled": True}},
		"dataSources": [
			{
				"type": "AzureComputerVision",
				"endpoint": azure_aivision_endpoint,
				"key": azure_aivision_key,
				"indexName": "ldv-index",
			}
		],
		"messages": [
			{"role": "system", "content": context},
			{"role": "user", "content": [prompt, {"image": base_64_encoded_image}]},
		],
		"max_tokens": 4000,
		"temperature": 0.7,
		"top_p": 1,
	}

	# Response
	response = requests.post(
		gpt4vision_endpoint, headers=headers, data=json.dumps(json_data)
	)

	# Testing the status code from the model response
	if response.status_code == 200:
		now = str(datetime.datetime.today().strftime("%d-%b-%Y %H:%M:%S"))
		st.write(f"Analysis of image: {image_file}")
		results = json.loads(response.text)
		st.write("\033[1;31;34m")
		st.write(results["choices"][0]["message"]["content"])
		
		prompt_tokens = results["usage"]["prompt_tokens"]
		completion_tokens = results["usage"]["completion_tokens"]
		total_tokens = results["usage"]["total_tokens"]

		st.write("\n\033[1;31;32mDone:", now)
		st.write(f"Prompt tokens = {prompt_tokens} | Completion tokens = {completion_tokens} | Total tokens = {total_tokens}")
		st.write("\n[Note] These results are generated by an AI")
		st.write("\033[0m")
		
		return results
	
	elif response.status_code == 429:
		st.write("[429 Error] Too many requests. Please wait a couple of seconds and try again.\n")
		st.write(json.loads(response.text))

	else:
		st.write(f"[Error] Error code: {response.status_code}\n")
		st.write(json.loads(response.text))

try:
	st.title("test_tabella")
	

except Exception as e:
	st.error(traceback.format_exc())